# Welcome to your prefect.yaml file! You can use this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: datapipeline
prefect-version: 3.1.0

# build section allows you to manage and build docker images
build: null

# push section allows you to manage if and how this project is uploaded to remote locations
push: null

# pull section allows you to provide instructions for cloning this project in remote locations
pull:
- prefect.deployments.steps.set_working_directory:
    directory: D:\ML\Notebooks\dbt_project\datapipeline

# the deployments section allows you to provide configuration for deploying flows
deployments:
- name: datapipeline_deploy
  version: "1"
  tags: []
  description: Deploying Datapipeline that will run DBT run and test commands and materialize the views and tables on snowflake
  schedule:
    cron: "0 0 * * *"
    timezone: "UTC"
  flow_name: dbt_command_flow
  entrypoint: prefect_flow.py:dbt_command_flow
  parameters: {}
  work_pool:
    name: null
    work_queue_name: null
    job_variables: {}
